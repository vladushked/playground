{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bit29e064361c954e90adf267cf1683fa25",
   "display_name": "Python 3.8.5 64-bit",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyper-parameters \n",
    "# input_size = 784 # 28x28\n",
    "num_classes = 10\n",
    "num_epochs = 2\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "input_size = 28\n",
    "sequence_length = 28\n",
    "hidden_size = 128\n",
    "num_layers = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from six.moves import urllib    \n",
    "opener = urllib.request.build_opener()\n",
    "opener.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
    "urllib.request.install_opener(opener)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[ADownloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n",
      "\n",
      "  0%|          | 0/9912422 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 16384/9912422 [00:00<01:14, 132679.22it/s]\u001b[A\n",
      "  1%|          | 81920/9912422 [00:00<00:24, 401763.36it/s]\u001b[A\n",
      "  1%|▏         | 147456/9912422 [00:00<00:19, 509027.51it/s]\u001b[A\n",
      "  3%|▎         | 303104/9912422 [00:00<00:10, 899585.34it/s]\u001b[A\n",
      "  6%|▌         | 565248/9912422 [00:01<00:06, 1486424.84it/s]\u001b[A\n",
      "  9%|▉         | 917504/9912422 [00:01<00:04, 2126516.97it/s]\u001b[A\n",
      " 15%|█▌        | 1499136/9912422 [00:01<00:02, 3292542.39it/s]\u001b[A\n",
      " 20%|█▉        | 1974272/9912422 [00:01<00:02, 3741149.12it/s]\u001b[A\n",
      " 24%|██▍       | 2359296/9912422 [00:01<00:02, 3752040.64it/s]\u001b[A\n",
      " 29%|██▉       | 2875392/9912422 [00:01<00:01, 4159323.57it/s]\u001b[A\n",
      " 33%|███▎      | 3293184/9912422 [00:01<00:01, 3412664.68it/s]\u001b[A\n",
      " 40%|████      | 3973120/9912422 [00:01<00:01, 3957611.97it/s]\u001b[A\n",
      " 44%|████▍     | 4382720/9912422 [00:01<00:01, 3849485.93it/s]\u001b[A\n",
      " 49%|████▊     | 4816896/9912422 [00:02<00:01, 3880411.03it/s]\u001b[A\n",
      " 53%|█████▎    | 5218304/9912422 [00:02<00:01, 3297770.13it/s]\u001b[A\n",
      " 56%|█████▌    | 5570560/9912422 [00:02<00:01, 2795291.34it/s]\u001b[A\n",
      " 60%|█████▉    | 5898240/9912422 [00:02<00:01, 2853917.59it/s]\u001b[A\n",
      " 63%|██████▎   | 6209536/9912422 [00:02<00:01, 2905434.54it/s]\u001b[A\n",
      " 66%|██████▌   | 6512640/9912422 [00:02<00:01, 2158614.94it/s]\u001b[A\n",
      " 70%|██████▉   | 6905856/9912422 [00:02<00:01, 2503212.05it/s]\u001b[A\n",
      " 81%|████████  | 7995392/9912422 [00:03<00:00, 4415699.05it/s]\u001b[A\n",
      " 86%|████████▌ | 8519680/9912422 [00:03<00:00, 2367585.63it/s]\u001b[A\n",
      " 99%|█████████▉| 9854976/9912422 [00:03<00:00, 4025182.41it/s]\u001b[AExtracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[ADownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "\n",
      "\n",
      "  0%|          | 0/28881 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 24576/28881 [00:00<00:00, 239198.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\u001b[AExtracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/1648877 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|          | 16384/1648877 [00:00<00:13, 125188.51it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  3%|▎         | 49152/1648877 [00:00<00:06, 229816.34it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  6%|▋         | 106496/1648877 [00:00<00:04, 375226.73it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 14%|█▍        | 229376/1648877 [00:00<00:02, 679439.18it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 26%|██▋       | 434176/1648877 [00:00<00:01, 1137082.33it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 34%|███▍      | 565248/1648877 [00:00<00:00, 1169125.78it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 41%|████      | 679936/1648877 [00:01<00:00, 1122243.02it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 61%|██████    | 999424/1648877 [00:01<00:00, 1748484.92it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 72%|███████▏  | 1187840/1648877 [00:01<00:00, 1524993.01it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 85%|████████▍ | 1400832/1648877 [00:01<00:00, 1672815.05it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 98%|█████████▊| 1622016/1648877 [00:01<00:00, 1815140.19it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[AExtracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/4542 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[AExtracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# MNIST dataset \n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', \n",
    "                                           train=True, \n",
    "                                           transform=transforms.ToTensor(),  \n",
    "                                           download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', \n",
    "                                          train=False, \n",
    "                                          transform=transforms.ToTensor())\n",
    "\n",
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "0it [1:30:41, ?it/s]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([100, 1, 28, 28])"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "iter(test_loader).next()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully connected neural network with one hidden layer\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(RNN, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        # -> x needs to be: (batch_size, seq, input_size)\n",
    "        \n",
    "        # or:\n",
    "        #self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        #self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Set initial hidden states (and cell states for LSTM)\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        #c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        \n",
    "        # x: (n, 28, 28), h0: (2, n, 128)\n",
    "        \n",
    "        # Forward propagate RNN\n",
    "        out, _ = self.rnn(x, h0)  \n",
    "        # or:\n",
    "        #out, _ = self.lstm(x, (h0,c0))  \n",
    "        \n",
    "        # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        # out: (n, 28, 128)\n",
    "        \n",
    "        # Decode the hidden state of the last time step\n",
    "        out = out[:, -1, :]\n",
    "        # out: (n, 128)\n",
    "         \n",
    "        out = self.fc(out)\n",
    "        # out: (n, 10)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(input_size, hidden_size, num_layers, num_classes).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch [1/2], Step [100/600], Loss: 0.7935\n",
      "Epoch [1/2], Step [200/600], Loss: 0.7263\n",
      "Epoch [1/2], Step [300/600], Loss: 0.4443\n",
      "Epoch [1/2], Step [400/600], Loss: 0.4806\n",
      "Epoch [1/2], Step [500/600], Loss: 0.4036\n",
      "Epoch [1/2], Step [600/600], Loss: 0.4303\n",
      "Epoch [2/2], Step [100/600], Loss: 0.3552\n",
      "Epoch [2/2], Step [200/600], Loss: 0.2609\n",
      "Epoch [2/2], Step [300/600], Loss: 0.2514\n",
      "Epoch [2/2], Step [400/600], Loss: 0.2695\n",
      "Epoch [2/2], Step [500/600], Loss: 0.2530\n",
      "Epoch [2/2], Step [600/600], Loss: 0.1610\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "n_total_steps = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):  \n",
    "        # origin shape: [N, 1, 28, 28]\n",
    "        # resized: [N, 28, 28]\n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy of the network on the 10000 test images: 94.92 %\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        # max returns (value ,index)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network on the 10000 test images: {acc} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}