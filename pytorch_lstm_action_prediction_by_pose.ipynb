{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bit29e064361c954e90adf267cf1683fa25",
   "display_name": "Python 3.8.5 64-bit",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "KeyboardInterrupt: ",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a6857fca8dda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mUSE_GLOBAL_DEPS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0m_load_global_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;31m# Appease the type checker; ordinarily this binding is inserted by the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: KeyboardInterrupt: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')\n",
    "LABELS = [    \n",
    "    \"JUMPING\",\n",
    "    \"JUMPING_JACKS\",\n",
    "    \"BOXING\",\n",
    "    \"WAVING_2HANDS\",\n",
    "    \"WAVING_1HAND\",\n",
    "    \"CLAPPING_HANDS\"\n",
    "\n",
    "] \n",
    "DATASET_PATH = \"poses_dataset/\"\n",
    "\n",
    "X_train_path = DATASET_PATH + \"X_train.txt\"\n",
    "X_test_path = DATASET_PATH + \"X_test.txt\"\n",
    "\n",
    "y_train_path = DATASET_PATH + \"Y_train.txt\"\n",
    "y_test_path = DATASET_PATH + \"Y_test.txt\"\n",
    "\n",
    "# Hyper-parameters \n",
    "# input_size = 784 # 28x28\n",
    "num_classes = 6\n",
    "num_epochs = 2\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "input_size = 36\n",
    "sequence_length = 32\n",
    "hidden_size = 128\n",
    "num_layers = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [  \"j0_x\",  \"j0_y\", \"j1_x\", \"j1_y\" , \"j2_x\", \"j2_y\", \"j3_x\", \"j3_y\", \"j4_x\", \"j4_y\", \"j5_x\", \"j5_y\", \"j6_x\", \"j6_y\", \"j7_x\", \"j7_y\", \"j8_x\", \"j8_y\", \"j9_x\", \"j9_y\", \"j10_x\", \"j10_y\", \"j11_x\", \"j11_y\", \"j12_x\", \"j12_y\", \"j13_x\", \"j13_y\", 'j14_x', \"j14_y\", \"j15_x\", \"j15_y\", \"j16_x\", \"j16_y\", \"j17_x\", \"j17_y\" ]\n",
    "x_train_data = pd.read_csv(X_train_path, sep=\",\", names=column_names, header=None, dtype=np.float32)\n",
    "x_test_data = pd.read_csv(X_test_path, sep=\",\", names=column_names, header=None, dtype=np.float32)\n",
    "y_train_data = pd.read_csv(y_train_path, names=[\"labels\"], dtype=np.int_)\n",
    "y_test_data = pd.read_csv(y_test_path, names=[\"labels\"], dtype=np.int_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      j0_x     j0_y     j1_x     j1_y     j2_x     j2_y     j3_x     j3_y  \\\n",
       "0  295.914  161.579  307.693  203.413  281.546  203.368  274.997  251.562   \n",
       "1  295.855  161.600  307.684  203.408  281.529  203.385  274.989  251.574   \n",
       "2  293.296  161.620  307.655  203.410  280.228  203.382  274.986  251.591   \n",
       "3  291.978  161.658  307.619  204.678  278.918  204.659  275.001  254.114   \n",
       "4  288.063  168.120  306.362  209.835  276.384  211.108  275.010  255.461   \n",
       "\n",
       "      j4_x     j4_y  ...    j13_x    j13_y    j14_x    j14_y    j15_x  \\\n",
       "0  267.194  293.253  ...  328.528  411.922  294.546  156.420  305.002   \n",
       "1  267.191  291.961  ...  328.493  410.630  293.252  157.686  303.706   \n",
       "2  267.262  289.373  ...  328.522  411.946  289.374  157.686  299.798   \n",
       "3  269.794  289.363  ...  328.479  411.947  288.101  157.727  298.487   \n",
       "4  275.003  294.581  ...  329.774  411.884  286.774  161.596  297.133   \n",
       "\n",
       "     j15_y  j16_x  j16_y    j17_x    j17_y  \n",
       "0  156.418    0.0    0.0  318.083  161.632  \n",
       "1  157.706    0.0    0.0  318.024  161.654  \n",
       "2  157.714    0.0    0.0  316.776  161.679  \n",
       "3  158.985    0.0    0.0  316.720  161.697  \n",
       "4  161.601    0.0    0.0  315.402  166.840  \n",
       "\n",
       "[5 rows x 36 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>j0_x</th>\n      <th>j0_y</th>\n      <th>j1_x</th>\n      <th>j1_y</th>\n      <th>j2_x</th>\n      <th>j2_y</th>\n      <th>j3_x</th>\n      <th>j3_y</th>\n      <th>j4_x</th>\n      <th>j4_y</th>\n      <th>...</th>\n      <th>j13_x</th>\n      <th>j13_y</th>\n      <th>j14_x</th>\n      <th>j14_y</th>\n      <th>j15_x</th>\n      <th>j15_y</th>\n      <th>j16_x</th>\n      <th>j16_y</th>\n      <th>j17_x</th>\n      <th>j17_y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>295.914</td>\n      <td>161.579</td>\n      <td>307.693</td>\n      <td>203.413</td>\n      <td>281.546</td>\n      <td>203.368</td>\n      <td>274.997</td>\n      <td>251.562</td>\n      <td>267.194</td>\n      <td>293.253</td>\n      <td>...</td>\n      <td>328.528</td>\n      <td>411.922</td>\n      <td>294.546</td>\n      <td>156.420</td>\n      <td>305.002</td>\n      <td>156.418</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>318.083</td>\n      <td>161.632</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>295.855</td>\n      <td>161.600</td>\n      <td>307.684</td>\n      <td>203.408</td>\n      <td>281.529</td>\n      <td>203.385</td>\n      <td>274.989</td>\n      <td>251.574</td>\n      <td>267.191</td>\n      <td>291.961</td>\n      <td>...</td>\n      <td>328.493</td>\n      <td>410.630</td>\n      <td>293.252</td>\n      <td>157.686</td>\n      <td>303.706</td>\n      <td>157.706</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>318.024</td>\n      <td>161.654</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>293.296</td>\n      <td>161.620</td>\n      <td>307.655</td>\n      <td>203.410</td>\n      <td>280.228</td>\n      <td>203.382</td>\n      <td>274.986</td>\n      <td>251.591</td>\n      <td>267.262</td>\n      <td>289.373</td>\n      <td>...</td>\n      <td>328.522</td>\n      <td>411.946</td>\n      <td>289.374</td>\n      <td>157.686</td>\n      <td>299.798</td>\n      <td>157.714</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>316.776</td>\n      <td>161.679</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>291.978</td>\n      <td>161.658</td>\n      <td>307.619</td>\n      <td>204.678</td>\n      <td>278.918</td>\n      <td>204.659</td>\n      <td>275.001</td>\n      <td>254.114</td>\n      <td>269.794</td>\n      <td>289.363</td>\n      <td>...</td>\n      <td>328.479</td>\n      <td>411.947</td>\n      <td>288.101</td>\n      <td>157.727</td>\n      <td>298.487</td>\n      <td>158.985</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>316.720</td>\n      <td>161.697</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>288.063</td>\n      <td>168.120</td>\n      <td>306.362</td>\n      <td>209.835</td>\n      <td>276.384</td>\n      <td>211.108</td>\n      <td>275.010</td>\n      <td>255.461</td>\n      <td>275.003</td>\n      <td>294.581</td>\n      <td>...</td>\n      <td>329.774</td>\n      <td>411.884</td>\n      <td>286.774</td>\n      <td>161.596</td>\n      <td>297.133</td>\n      <td>161.601</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>315.402</td>\n      <td>166.840</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 36 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "x_train_data.head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "numpy.int64"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "type(y_train_data.iloc[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully connected neural network with one hidden layer\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        # -> x needs to be: (batch_size, seq, input_size)\n",
    "        \n",
    "        # or:\n",
    "        #self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        #self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Set initial hidden states (and cell states for LSTM)\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        \n",
    "        # x: (n, 28, 28), h0: (2, n, 128)\n",
    "        \n",
    "        # Forward propagate RNN\n",
    "        # out, _ = self.rnn(x, h0)  \n",
    "        # or:\n",
    "        out, _ = self.lstm(x, (h0,c0))  \n",
    "        \n",
    "        # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        # out: (n, 28, 128)\n",
    "        \n",
    "        # Decode the hidden state of the last time step\n",
    "        out = out[:, -1, :]\n",
    "        # out: (n, 128)\n",
    "         \n",
    "        out = self.fc(out)\n",
    "        # out: (n, 10)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM(input_size, hidden_size, num_layers, num_classes).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunker(x_seq, y_seq, seq_size, batch_size):\n",
    "    for batch_pos in range(0, len(y_seq), batch_size):\n",
    "        x_batch = list()\n",
    "        for pos in range(batch_size):\n",
    "            # print(x_seq.iloc[pos*seq_size:pos*seq_size + seq_size])\n",
    "            x_batch.append(x_seq.iloc[pos*seq_size:pos*seq_size + seq_size].values)\n",
    "        \n",
    "        yield torch.tensor(x_batch), torch.flatten(torch.tensor(y_seq.iloc[batch_pos:batch_pos + batch_size].values))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "for i, (x_batch, y_batch) in enumerate(chunker(x_test_data, y_test_data, sequence_length, batch_size)):\n",
    "    if i == 1:\n",
    "        break\n",
    "    print(_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch [1/2], Step [1/22625], Loss: 1.6652\n",
      "Epoch [2/2], Step [1/22625], Loss: 1.7002\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "n_total_steps = y_train_data.shape[0]\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (x_batch, y_batch) in enumerate(chunker(x_test_data, y_test_data, sequence_length, batch_size)):  \n",
    "        # origin shape: [N, 1, 28, 28]\n",
    "        # resized: [N, 28, 28]\n",
    "        y_batch = y_batch.to(device)\n",
    "        x_batch = x_batch.to(device)\n",
    "        \n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(x_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
    "        break\n",
    "        # if (i+1) % 100 == 0:\n",
    "        #     print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
    "            # break\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy of the network on the 10000 test images: 94.92 %\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        # max returns (value ,index)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network on the 10000 test images: {acc} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}