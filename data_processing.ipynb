{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36964bit85ef42dc311540dbbdc2b3827db2c57f",
   "display_name": "Python 3.6.9 64-bit",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device('cpu')\n",
    "LABELS = [    \n",
    "    \"JUMPING\",\n",
    "    \"JUMPING_JACKS\",\n",
    "    \"BOXING\",\n",
    "    \"WAVING_2HANDS\",\n",
    "    \"WAVING_1HAND\",\n",
    "    \"CLAPPING_HANDS\"\n",
    "\n",
    "] \n",
    "DATASET_PATH = \"poses/\"\n",
    "\n",
    "X_train_path = \"shuffled_x_train_data\"\n",
    "X_test_path = DATASET_PATH + \"X_test.txt\"\n",
    "\n",
    "y_train_path = \"shuffled_y_train_data\"\n",
    "y_test_path = DATASET_PATH + \"Y_test.txt\"\n",
    "\n",
    "# Hyper-parameters \n",
    "# input_size = 784 # 28x28\n",
    "num_classes = 6\n",
    "num_epochs = 10\n",
    "train_batch_size = 125\n",
    "test_batch_size = 1\n",
    "learning_rate = 0.00001\n",
    "\n",
    "input_size = 36\n",
    "sequence_length = 32\n",
    "hidden_size = 200\n",
    "num_layers = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [  \"j0_x\",  \"j0_y\", \"j1_x\", \"j1_y\" , \"j2_x\", \"j2_y\", \"j3_x\", \"j3_y\", \"j4_x\", \"j4_y\", \"j5_x\", \"j5_y\", \"j6_x\", \"j6_y\", \"j7_x\", \"j7_y\", \"j8_x\", \"j8_y\", \"j9_x\", \"j9_y\", \"j10_x\", \"j10_y\", \"j11_x\", \"j11_y\", \"j12_x\", \"j12_y\", \"j13_x\", \"j13_y\", 'j14_x', \"j14_y\", \"j15_x\", \"j15_y\", \"j16_x\", \"j16_y\", \"j17_x\", \"j17_y\" ]\n",
    "# x_train_data = pd.read_csv(X_train_path, sep=\",\", names=column_names, header=None, dtype=np.float32)\n",
    "shuffled_x_train_data = pd.read_csv(X_train_path, sep=\"\\t\", dtype=np.float32)\n",
    "x_test_data = pd.read_csv(X_test_path, sep=\",\", names=column_names, header=None, dtype=np.float32)\n",
    "# y_train_data = p|d.read_csv(y_train_path, names=[\"labels\"], dtype=np.int_)\n",
    "shuffled_y_train_data = pd.read_csv(y_train_path, sep=\"\\t\", dtype=np.int_)\n",
    "y_test_data = pd.read_csv(y_test_path, names=[\"labels\"], dtype=np.int_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "    for i, column in enumerate(data):\n",
    "        if i % 2 == 0:\n",
    "            data[column] = data[column] / 640\n",
    "        else:\n",
    "            data[column] = data[column] / 480\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unnormalize(data):\n",
    "    for i, column in enumerate(data):\n",
    "        if i % 2 == 0:\n",
    "            data[column] = data[column] * 640\n",
    "        else:\n",
    "            data[column] = data[column] * 480\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       j0_x      j0_y      j1_x      j1_y      j2_x      j2_y      j3_x  \\\n",
       "0  0.480608  0.339533  0.499006  0.429050  0.458230  0.426417  0.445991   \n",
       "1  0.480573  0.339540  0.499003  0.429056  0.458214  0.426448  0.445981   \n",
       "2  0.478591  0.339481  0.498986  0.429035  0.456236  0.426415  0.445988   \n",
       "3  0.478508  0.336883  0.498959  0.426423  0.456230  0.426333  0.445983   \n",
       "4  0.476562  0.336775  0.497027  0.426348  0.454209  0.423727  0.445997   \n",
       "\n",
       "       j3_y      j4_x      j4_y  ...     j13_x     j13_y     j14_x     j14_y  \\\n",
       "0  0.521419  0.433775  0.597352  ...  0.527416  0.858235  0.476553  0.333940   \n",
       "1  0.521417  0.433775  0.594800  ...  0.527414  0.858202  0.476514  0.333948   \n",
       "2  0.524065  0.433777  0.597444  ...  0.527422  0.858233  0.472530  0.333890   \n",
       "3  0.521427  0.431887  0.597506  ...  0.527445  0.858206  0.470505  0.331300   \n",
       "4  0.521408  0.431880  0.597565  ...  0.527423  0.858217  0.470452  0.328621   \n",
       "\n",
       "      j15_x     j15_y  j16_x  j16_y     j17_x     j17_y  \n",
       "0  0.492905  0.333894    0.0    0.0  0.515238  0.336773  \n",
       "1  0.492866  0.333892    0.0    0.0  0.513323  0.336781  \n",
       "2  0.490823  0.333875    0.0    0.0  0.513273  0.336835  \n",
       "3  0.488778  0.331308    0.0    0.0  0.513252  0.336785  \n",
       "4  0.486744  0.331202    0.0    0.0  0.513173  0.336777  \n",
       "\n",
       "[5 rows x 36 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>j0_x</th>\n      <th>j0_y</th>\n      <th>j1_x</th>\n      <th>j1_y</th>\n      <th>j2_x</th>\n      <th>j2_y</th>\n      <th>j3_x</th>\n      <th>j3_y</th>\n      <th>j4_x</th>\n      <th>j4_y</th>\n      <th>...</th>\n      <th>j13_x</th>\n      <th>j13_y</th>\n      <th>j14_x</th>\n      <th>j14_y</th>\n      <th>j15_x</th>\n      <th>j15_y</th>\n      <th>j16_x</th>\n      <th>j16_y</th>\n      <th>j17_x</th>\n      <th>j17_y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.480608</td>\n      <td>0.339533</td>\n      <td>0.499006</td>\n      <td>0.429050</td>\n      <td>0.458230</td>\n      <td>0.426417</td>\n      <td>0.445991</td>\n      <td>0.521419</td>\n      <td>0.433775</td>\n      <td>0.597352</td>\n      <td>...</td>\n      <td>0.527416</td>\n      <td>0.858235</td>\n      <td>0.476553</td>\n      <td>0.333940</td>\n      <td>0.492905</td>\n      <td>0.333894</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.515238</td>\n      <td>0.336773</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.480573</td>\n      <td>0.339540</td>\n      <td>0.499003</td>\n      <td>0.429056</td>\n      <td>0.458214</td>\n      <td>0.426448</td>\n      <td>0.445981</td>\n      <td>0.521417</td>\n      <td>0.433775</td>\n      <td>0.594800</td>\n      <td>...</td>\n      <td>0.527414</td>\n      <td>0.858202</td>\n      <td>0.476514</td>\n      <td>0.333948</td>\n      <td>0.492866</td>\n      <td>0.333892</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.513323</td>\n      <td>0.336781</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.478591</td>\n      <td>0.339481</td>\n      <td>0.498986</td>\n      <td>0.429035</td>\n      <td>0.456236</td>\n      <td>0.426415</td>\n      <td>0.445988</td>\n      <td>0.524065</td>\n      <td>0.433777</td>\n      <td>0.597444</td>\n      <td>...</td>\n      <td>0.527422</td>\n      <td>0.858233</td>\n      <td>0.472530</td>\n      <td>0.333890</td>\n      <td>0.490823</td>\n      <td>0.333875</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.513273</td>\n      <td>0.336835</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.478508</td>\n      <td>0.336883</td>\n      <td>0.498959</td>\n      <td>0.426423</td>\n      <td>0.456230</td>\n      <td>0.426333</td>\n      <td>0.445983</td>\n      <td>0.521427</td>\n      <td>0.431887</td>\n      <td>0.597506</td>\n      <td>...</td>\n      <td>0.527445</td>\n      <td>0.858206</td>\n      <td>0.470505</td>\n      <td>0.331300</td>\n      <td>0.488778</td>\n      <td>0.331308</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.513252</td>\n      <td>0.336785</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.476562</td>\n      <td>0.336775</td>\n      <td>0.497027</td>\n      <td>0.426348</td>\n      <td>0.454209</td>\n      <td>0.423727</td>\n      <td>0.445997</td>\n      <td>0.521408</td>\n      <td>0.431880</td>\n      <td>0.597565</td>\n      <td>...</td>\n      <td>0.527423</td>\n      <td>0.858217</td>\n      <td>0.470452</td>\n      <td>0.328621</td>\n      <td>0.486744</td>\n      <td>0.331202</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.513173</td>\n      <td>0.336777</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 36 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# normalize(x_train_data)\n",
    "normalize(x_test_data).head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      labels\n",
       "0          0\n",
       "1          0\n",
       "2          0\n",
       "3          0\n",
       "4          0\n",
       "...      ...\n",
       "5746       5\n",
       "5747       5\n",
       "5748       5\n",
       "5749       5\n",
       "5750       5\n",
       "\n",
       "[5751 rows x 1 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5746</th>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>5747</th>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>5748</th>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>5749</th>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>5750</th>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n<p>5751 rows Ã— 1 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# y_train_data = y_train_data - 1\n",
    "y_test_data = y_test_data - 1\n",
    "y_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def shuffle_data(x_data, y_data):\n",
    "    length = y_data.shape[0]\n",
    "    shuffled_indexes = [i for i in range(length)]\n",
    "    shuffle(shuffled_indexes)\n",
    "    shuffled_y_data = pd.DataFrame()\n",
    "    shuffled_x_data = pd.DataFrame()\n",
    "    for i, index in enumerate(shuffled_indexes): \n",
    "        shuffled_y_data = shuffled_y_data.append(y_data.iloc[[index]], ignore_index=True)\n",
    "        shuffled_x_data = shuffled_x_data.append(x_data.iloc[index*32:index*32+32], ignore_index=True)\n",
    "        if (i % 1000 == 0):\n",
    "            print(f\"{i} done\")\n",
    "    return shuffled_x_data, shuffled_y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0 done\n",
      "1000 done\n",
      "2000 done\n",
      "3000 done\n",
      "4000 done\n",
      "5000 done\n"
     ]
    }
   ],
   "source": [
    "shuffled_x_test_data, shuffled_y_test_data = shuffle_data(x_test_data, y_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_x_test_data.to_csv(\"shuffled_x_test_data.csv\", sep='\\t', index=False)\n",
    "shuffled_y_test_data.to_csv(\"shuffled_y_test_data.csv\", sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully connected neural network with one hidden layer\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        # -> x needs to be: (batch_size, seq, input_size)\n",
    "        \n",
    "        # or:100\n",
    "        #self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        #self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Set initial hidden states (and cell states for LSTM)\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        \n",
    "        # x: (n, 28, 28), h0: (2, n, 128)\n",
    "        \n",
    "        # Forward propagate RNN\n",
    "        # out, _ = self.rnn(x, h0)  \n",
    "        # or:\n",
    "        out, _ = self.lstm(x, (h0,c0))  \n",
    "        \n",
    "        # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        # out: (n, 28, 128)\n",
    "        \n",
    "        # Decode the hidden state of the last time step\n",
    "        # out = out[:, -1, :]\n",
    "        # out: (n, 128)\n",
    "         \n",
    "        out = self.fc(out)\n",
    "        out = out[:, -1, :]\n",
    "        # out: (n, 10)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM(input_size, hidden_size, num_layers, num_classes).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunker(x_seq, y_seq, seq_size, batch_size):\n",
    "    for batch_pos in range(0, len(y_seq), batch_size):\n",
    "        x_batch = list()\n",
    "        for pos in range(batch_size):\n",
    "            # print(x_seq.iloc[pos*seq_size:pos*seq_size + seq_size])\n",
    "            x_batch.append(x_seq.iloc[pos*seq_size:pos*seq_size + seq_size].values)\n",
    "        \n",
    "        yield torch.tensor(x_batch), torch.flatten(torch.tensor(y_seq.iloc[batch_pos:batch_pos + batch_size].values))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "20000.0\n(20000, 1)\n2625.0\n(2625, 1)\n"
     ]
    }
   ],
   "source": [
    "y_train = shuffled_y_train_data.iloc[:int(shuffled_y_train_data.shape[0]*0.9 - 362)]\n",
    "x_train = shuffled_x_train_data.iloc[:int(y_train.shape[0]*32)]\n",
    "x_test = shuffled_x_train_data.iloc[x_train.shape[0]:]\n",
    "y_test = shuffled_y_train_data.iloc[y_train.shape[0]:]\n",
    "print(x_train.shape[0]/32)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape[0]/32)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch [1/10], Step [10/100], Loss: 1.7981\n",
      "Epoch [1/10], Step [20/100], Loss: 1.7932\n",
      "Epoch [1/10], Step [30/100], Loss: 1.7918\n",
      "Epoch [1/10], Step [40/100], Loss: 1.7940\n",
      "Epoch [1/10], Step [50/100], Loss: 1.7925\n",
      "Epoch [1/10], Step [60/100], Loss: 1.7857\n",
      "Epoch [1/10], Step [70/100], Loss: 1.7930\n",
      "Epoch [1/10], Step [80/100], Loss: 1.7901\n",
      "Epoch [1/10], Step [90/100], Loss: 1.7876\n",
      "Epoch [1/10], Step [100/100], Loss: 1.7894\n",
      "Accuracy: 16.825 %\n",
      "Accuracy: 23.2 %\n",
      "Epoch [2/10], Step [10/100], Loss: 1.7852\n",
      "Epoch [2/10], Step [20/100], Loss: 1.7835\n",
      "Epoch [2/10], Step [30/100], Loss: 1.7814\n",
      "Epoch [2/10], Step [40/100], Loss: 1.7741\n",
      "Epoch [2/10], Step [50/100], Loss: 1.7789\n",
      "Epoch [2/10], Step [60/100], Loss: 1.7738\n",
      "Epoch [2/10], Step [70/100], Loss: 1.7742\n",
      "Epoch [2/10], Step [80/100], Loss: 1.7765\n",
      "Epoch [2/10], Step [90/100], Loss: 1.7704\n",
      "Epoch [2/10], Step [100/100], Loss: 1.7643\n",
      "Accuracy: 22.23 %\n",
      "Accuracy: 23.2 %\n",
      "Epoch [3/10], Step [10/100], Loss: 1.7551\n",
      "Epoch [3/10], Step [20/100], Loss: 1.7626\n",
      "Epoch [3/10], Step [30/100], Loss: 1.7585\n",
      "Epoch [3/10], Step [40/100], Loss: 1.7114\n",
      "Epoch [3/10], Step [50/100], Loss: 1.7471\n",
      "Epoch [3/10], Step [60/100], Loss: 1.7554\n",
      "Epoch [3/10], Step [70/100], Loss: 1.7329\n",
      "Epoch [3/10], Step [80/100], Loss: 1.7643\n",
      "Epoch [3/10], Step [90/100], Loss: 1.7534\n",
      "Epoch [3/10], Step [100/100], Loss: 1.7344\n",
      "Accuracy: 22.23 %\n",
      "Accuracy: 23.2 %\n",
      "Epoch [4/10], Step [10/100], Loss: 1.7269\n",
      "Epoch [4/10], Step [20/100], Loss: 1.7608\n",
      "Epoch [4/10], Step [30/100], Loss: 1.7580\n",
      "Epoch [4/10], Step [40/100], Loss: 1.6914\n",
      "Epoch [4/10], Step [50/100], Loss: 1.7466\n",
      "Epoch [4/10], Step [60/100], Loss: 1.7570\n",
      "Epoch [4/10], Step [70/100], Loss: 1.7327\n",
      "Epoch [4/10], Step [80/100], Loss: 1.7640\n",
      "Epoch [4/10], Step [90/100], Loss: 1.7531\n",
      "Epoch [4/10], Step [100/100], Loss: 1.7345\n",
      "Accuracy: 22.23 %\n",
      "Accuracy: 23.2 %\n",
      "Epoch [5/10], Step [10/100], Loss: 1.7269\n",
      "Epoch [5/10], Step [20/100], Loss: 1.7606\n",
      "Epoch [5/10], Step [30/100], Loss: 1.7579\n",
      "Epoch [5/10], Step [40/100], Loss: 1.6910\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-3698ebdaefb4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0;31m# print(outputs.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-f0cfcde97025>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m# out, _ = self.rnn(x, h0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# or:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# out: tensor of shape (batch_size, seq_length, hidden_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    580\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 582\u001b[0;31m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    583\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "n_total_steps = int(y_train.shape[0] / 200)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    correct = 0\n",
    "    for i, (x_batch, y_batch) in enumerate(chunker(x_train, y_train, sequence_length, 200)):  \n",
    "        # origin shape: [N, 1, 28, 28]\n",
    "        # resized: [N, 28, 28]\n",
    "        y_batch = y_batch.to(device)\n",
    "        x_batch = x_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        outputs = model(x_batch)\n",
    "        # print(outputs.shape)\n",
    "        \n",
    "        loss = criterion(outputs, y_batch)\n",
    "        # print(loss.item())\n",
    "        # Backward and optimize\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # max returns (value ,index)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        # print(predicted.shape)\n",
    "        correct += (predicted == y_batch).sum().item()\n",
    "        if (i+1) % 10 == 0:\n",
    "            \n",
    "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
    "    acc = 100.0 * correct / y_train.shape[0]\n",
    "    print (f'Accuracy: {acc} %')\n",
    "    # Test the model\n",
    "    # In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        for i, (x_batch, y_batch) in enumerate(chunker(x_test, y_test, sequence_length, 125)):  \n",
    "            # origin shape: [N, 1, 28, 28]\n",
    "            # resized: [N, 28, 28]\n",
    "            y_batch = y_batch.to(device)\n",
    "            x_batch = x_batch.to(device)\n",
    "            outputs = model(x_batch)\n",
    "            \n",
    "            # max returns (value ,index)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct += (predicted == y_batch).sum().item()\n",
    "        acc = 100.0 * correct / y_test.shape[0]\n",
    "        print(f'Accuracy: {acc} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}